<!DOCTYPE html>
<html>
  <head>
    <title>Interpretable ML</title>
    <meta charset="utf-8">
    <meta name="author" content="Brian Carter, ARA, Optum Ireland" />
    <link href="libs/remark-css/example.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Interpretable ML
## with LIME
### Brian Carter, ARA, Optum Ireland
### 14-Jun-2017

---


background-image: url(images/lime-fruit4.jpeg)
background-position: 90% 50%
background-size: 50% 50%
class: left, top

&lt;br&gt;

### What is ML Interpretability ?

### Why ML Interpretability ? 

### What is LIME ?

### Lets see it in action!

### Can it be useful?

### Really can it be useful ?

### Further Resources 

???

Notes here

p opens presenter mode which shows you a preview of the next slide, a timer, and any slide notes you have written. 
c will clone the slideshow in a separate tab for your viewers. The cloned slideshow changes slides along with you in presenter mode.

---
# What is ML Interpretability

---
# Why ML Interpretability


---
background-image: url(images/headlines.jpg)
background-size: 100% 100%

---
# What is LIME

### LIME

- Local 

- Interpretable

- Model-Agnostic

- Explanation

--

- `\(\xi(x) = \underset{g\in G}{\operatorname{argmax}} \ell(f, g, \pi_x) + \Omega(g)\)`

---
background-image: url(images/lime-flow2.jpg)
background-position: 90% 50%
background-size: 50% 50%
# What is LIME

### LIME

- Local 

- Interpretable

- Model-Agnostic

- Explanation

- `\(\xi(x) = \underset{g\in G}{\operatorname{argmax}} \ell(f, g, \pi_x) + \Omega(g)\)`

---
# Lets see in action

The Forest Data Set: &lt;font size = "3"&gt;&lt;i&gt;(What types of trees grow in an area based on the surrounding characteristics?)&lt;/i&gt;&lt;/font&gt;

.pull-left[
**Variables**
&lt;font size="2"&gt;
&lt;ul&gt; Elevatation (elevation in meters) &lt;/ul&gt;
&lt;ul&gt; Aspect (direction of slope in degrees azimuth) &lt;/ul&gt;
&lt;ul&gt; Slope (slope in degrees) &lt;/ul&gt;
&lt;ul&gt; HD.Hydro (horz. dist to nearest surface water) &lt;/ul&gt;
&lt;ul&gt; VD.Hydro (vert. dist to water) &lt;/ul&gt;
&lt;ul&gt; HD.Road (horz. dist to nearest roadway) &lt;/ul&gt; 
&lt;ul&gt; HD.Fire (horz. dist to nearest wildfire ignition points) &lt;/ul&gt;
&lt;ul&gt; HS.9am ((0 to 255 index): Hillshade index at 9am, summer solstice) &lt;/ul&gt;
&lt;ul&gt; HS.noon &lt;/ul&gt;
&lt;ul&gt; HS.3pm  &lt;/ul&gt;
&lt;ul&gt; &lt;i&gt;(Wilderness Area, Soil Type, Geological Zone) &lt;/i&gt; categorical, omitted. &lt;/ul&gt;
&lt;/font&gt;
]

.pull-right[
**Target**

&lt;font size="2"&gt;
&lt;ul&gt; Cover Type (7 types of trees) &lt;/ul&gt;
&lt;ul&gt; lodge.pine (48%),  spruce.fir (37%),  ponder.pine (6%),  krummholz(3%),  others(&lt; 3%)&lt;/ul&gt;
&lt;ul&gt; 581,012 instances (sampled 10,000) &lt;/ul&gt;
&lt;/font&gt;
]

---

# R Plots

- Lime is available for [Python](https://github.com/marcotcr/lime) and more recently Thomas Lin Pedersen has implemented in [R](https://github.com/thomasp85/lime).


```r
pip install lime
devtools::install_github("thomasp85/lime")
```

#### Python Implementation


```python
import lime
import lime.lime_tabular

explainer = lime.lime_tabular.LimeTabularExplainer(train,
   feature_names= names(train.X), 
   class_names= train.y, discretize_continuous=True)
   
i = np.random.randint(0, test.X[0])
exp = explainer.explain_instance(test.X[i], model.predict_proba, 
      num_features=2, top_labels=1)

#In a Jupyter Notebook
exp.show_in_notebook(show_table=True, show_all=False)
```

---

#### R Implementation


```r
library(lime)

explainer &lt;- lime(train.data, tuned.model , 
                  bin_continuous = TRUE, 
                  n_bins = 4, n_permutations = 1000)

#Grab 1 or more examples to explain
test.example &lt;- sample_n(test.data, 1)

explained.example &lt;- explainer(test.example, 
                               n_labels = 2, n_features = 5, feature_select = "auto")
plot_features(expalined.exampled, ncol = 2)
```
--
&lt;font size="3"&gt;

LIME works with all models that have prediction probabilities. (R, models that work with &lt;mark&gt;predict(type = "prob")&lt;/mark&gt; , Python models that have &lt;mark&gt;predict_proba()&lt;/mark&gt; method). 


&lt;ul&gt; &lt;span style="color: red; background-color: yellow"&gt;bin_countinous&lt;/span&gt; should continous features be binned. Default is 4 bins. &lt;/ul&gt;

&lt;ul&gt; &lt;span style="color: red; background-color: yellow"&gt;n_permutations&lt;/span&gt; the number of permutations to generate for each row to be expalined.&lt;/ul&gt;

&lt;ul&gt;&lt;span style="color: red; background-color: yellow"&gt;n_labels&lt;/span&gt; how many labels in the target? Do you want to see all probabilites &lt;/ul&gt;

&lt;ul&gt;  &lt;span style="color: red; background-color: yellow"&gt;n_features&lt;/span&gt; How many features to use in the explanatory function? &lt;/ul&gt;

&lt;ul&gt;  &lt;span style="color: red; background-color: yellow"&gt;feature_select&lt;/span&gt; Default is &lt;i&gt;auto&lt;/i&gt;. If &lt;span style="color: red; background-color: yellow"&gt;n_features &lt;= 6&lt;/span&gt; uses &lt;i&gt;forward selection&lt;/i&gt;. Can also specify &lt;b&gt;feature_select&lt;/b&gt; = c("forward_selection", "highest_weights", "lasso_path")&lt;/ul&gt;

&lt;/font&gt;
---
class: top
background-image: url(images/lime-output/explain-output.png)
background-size: 100% 40%
background-position: 100% 50%

#### LIME Output (R)



```
##   X Elevation Aspect Slope HD.Hydro VD.Hydro HD.Road HD.Fire HS.9am
## 1 1      2950     99    13       95        8    2010     241    221
##   HS.noon HS.3pm     target
## 1     108   2732 lodge.pine
```

&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;

--
 
&lt;font size="3"&gt;

&lt;ul&gt; &lt;i&gt;Cover Type&lt;/i&gt; has been correctly predicted to be &lt;b&gt;Lodgepole Pine&lt;/b&gt;&lt;/ul&gt;

&lt;ul&gt; Elevation = 2950 is between 2810 &amp; 3001. From permutated data, this supports this class.&lt;/ul&gt;

&lt;ul&gt; HD Hyrdo = 95. This does not support the true class. It is more associated with class &lt;b&gt; Spruce Fir &lt;/b&gt;&lt;/ul&gt;

--

&lt;ul&gt; Lets Recap - how did we get here &lt;/ul&gt;


???
Write down good explanation here. 
 
---
background-image: url(images/lime-output/all-correct-3-models.png)
background-size: 100% 80%
background-position: 50% 80%

### Compare Models - All Correct

---
background-image: url(images/lime-output/all-wrong-3-models.png)
background-size: 100% 80%
background-position: 50% 80%

### Compare Models - All Wrong

---
background-image: url(images/lime-output/xgb-wrong-models.png)
background-size: 100% 80%
background-position: 50% 80%

### Compare Models - XGB Wrong

---
# Really can it be useful ?

- exploration phase 

![](images/DinoSequential.gif)

.footnote[https://github.com/stephlocke/datasauRus, Alberto Cairo

https://en.wikipedia.org/wiki/Anscombe%27s_quartet, Francis Anscombe]

???
- The Datasaurus Dozen show us why visualisation is important -- summary statistics can be the same but distributions can be very different
- Datasaurus was created by Alberto Cairo
- Fun alternative to Anscombe Quartet - 
https://en.wikipedia.org/wiki/Anscombe%27s_quartet
- Anscombe Quartet  four datasets (1973) that have nearly identical simple descriptive statistics, yet appear very different when graphed. 

---
background-image: url(images/links2.jpeg)
background-position: 0% 0%
background-size: 25% 25%
class: left, top

&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;

https://github.com/iBrianCarter/lime-exploration.git

### SlideDecks, Videos &amp; Talks
- [Demystifying Machine Learning using LIME](https://www.slideshare.net/albahnsen/demystifying-machine-learning-using-lime) - 
Alejandro Correa Bahnsen
- [Interpretable Machine Learning](https://www.youtube.com/watch?v=u9UUWqVquXo) - Patrick Hall, H2o.
- [Data Skeptic](https://dataskeptic.com/blog/episodes/2016/trusting-machine-learning-models-with-lime) - Marco Tulio Ribeiro, author of LIME.

### Articles

- [Interpreting Machine Learning](https://www.oreilly.com/ideas/ideas-on-interpreting-machine-learning) - Patrick Hall, Wen Phan, SriSatish Ambati, H2o.
- [THe Financial World Wants to Open Black Boxes](https://www.technologyreview.com/s/604122/the-financial-world-wants-to-open-ais-black-boxes/?imm_mid=0f134c&amp;cmp=em-na-na-na-newsltr_fintech_20170501) - Will Knight, MIT
- [The Dark Secret at the Heart of AI](https://www.technologyreview.com/s/604087/the-dark-secret-at-the-heart-of-ai/) - Will Knight, MIT
- [DARPA Working on Making AI more Trustworthy](https://futurism.com/darpa-working-make-ai-more-trustworthy/)

---
### Code Examples

- Python
  - [Examples from Marco Tulio Riberio](https://github.com/marcotcr/lime/tree/master/doc/notebooks)
  - [Demystifying Maching Learning - Jupyter Notebook](http://nbviewer.jupyter.org/github/albahnsen/Talk_Demystifying_Machine_Learning/blob/master/Demystifying_Machine_Learning_using_LIME.ipynb)
- R
  - [LIME R package](https://github.com/thomasp85/lime)
  - [Explaining complex machine learning models with LIME](https://shiring.github.io/machine_learning/2017/04/23/lime)
  - [LIME with Shiny](https://github.com/merrillrudd/LIME_shiny)

### Other Approaches

- [FairML](http://blog.fastforwardlabs.com/2017/03/09/fairml-auditing-black-box-predictive-models.html) - Julius Adebayo, uses perturbation like LIME. 
- [Explainable Artificial Intelligence,XAI](http://www.darpa.mil/program/explainable-artificial-intelligence) - David Gunning, DARPA. Comprehensive review of active research.
- [NeuroDecisionâ„¢](https://www.youtube.com/watch?v=SitMy5oeN_A) - commerical application. Excellent video for explaining ML to lay person.

### Conferences
---
background-image: url(images/whi.png)
background-size: 100% 100%

---
class: center, middle, inverse
background-image: url(images/unicorn.jpeg)
background-size: 30% 30%

## Thank you for your attention
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;
### Any Questions ?


???
Computer Age Statistical Inference - Trevor Hastie, Bradley Efron
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {window.dispatchEvent(new Event('resize'));});</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
});
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
